{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e96fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Swift GO 14\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc33a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of img folder:\n",
      "  ðŸ“ test/\n",
      "    Contents of test/:\n",
      "      ðŸ“ daisy/\n",
      "      ðŸ“ dandelion/\n",
      "  ðŸ“ train/\n",
      "    Contents of train/:\n",
      "      ðŸ“ daisy/\n",
      "      ðŸ“ dandelion/\n",
      "  ðŸ“ valid/\n",
      "    Contents of valid/:\n",
      "      ðŸ“ daisy/\n",
      "      ðŸ“ dandelion/\n",
      "\n",
      "Total items: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if img folder exists and list its contents\n",
    "if os.path.exists('img'):\n",
    "    print(\"Contents of img folder:\")\n",
    "    for item in os.listdir('img'):\n",
    "        item_path = os.path.join('img', item)\n",
    "        if os.path.isfile(item_path):\n",
    "            print(f\"  ðŸ“„ {item}\")\n",
    "        elif os.path.isdir(item_path):\n",
    "            print(f\"  ðŸ“ {item}/\")\n",
    "            # Print contents of subdirectory\n",
    "            print(f\"    Contents of {item}/:\")\n",
    "            try:\n",
    "                for subitem in os.listdir(item_path):\n",
    "                    subitem_path = os.path.join(item_path, subitem)\n",
    "                    if os.path.isfile(subitem_path):\n",
    "                        print(f\"      ðŸ“„ {subitem}\")\n",
    "                    elif os.path.isdir(subitem_path):\n",
    "                        print(f\"      ðŸ“ {subitem}/\")\n",
    "            except PermissionError:\n",
    "                print(f\"      âŒ Permission denied\")\n",
    "    \n",
    "    # Show total number of items\n",
    "    total_items = len(os.listdir('img'))\n",
    "    print(f\"\\nTotal items: {total_items}\")\n",
    "else:\n",
    "    print(\"img folder does not exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182f6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ test:\n",
      "  ðŸŒ¼ Daisy folder: 77 images\n",
      "  ðŸŒ» Dandelion folder: 105 images\n",
      "  ðŸ“Š Total: 182\n",
      "\n",
      "ðŸ“ train:\n",
      "  ðŸŒ¼ Daisy folder: 529 images\n",
      "  ðŸŒ» Dandelion folder: 746 images\n",
      "  ðŸ“Š Total: 1275\n",
      "\n",
      "ðŸ“ valid:\n",
      "  ðŸŒ¼ Daisy folder: 163 images\n",
      "  ðŸŒ» Dandelion folder: 201 images\n",
      "  ðŸ“Š Total: 364\n",
      "\n",
      "========================================\n",
      "OVERALL SUMMARY:\n",
      "ðŸŒ¼ Total Daisy images: 769\n",
      "ðŸŒ» Total Dandelion images: 1052\n",
      "ðŸ“Š Grand Total: 1821\n"
     ]
    }
   ],
   "source": [
    "# Count daisy and dandelion images in each folder\n",
    "if os.path.exists('img'):\n",
    "    for folder_name in os.listdir('img'):\n",
    "        folder_path = os.path.join('img', folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\nðŸ“ {folder_name}:\")\n",
    "            \n",
    "            daisy_count = 0\n",
    "            dandelion_count = 0\n",
    "            \n",
    "            try:\n",
    "                # Check if there are daisy and dandelion subfolders\n",
    "                subfolders = [item for item in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, item))]\n",
    "                \n",
    "                for subfolder in subfolders:\n",
    "                    subfolder_lower = subfolder.lower()\n",
    "                    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                    \n",
    "                    if 'daisy' in subfolder_lower:\n",
    "                        try:\n",
    "                            daisy_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "                            daisy_count = len(daisy_files)\n",
    "                            print(f\"  ðŸŒ¼ Daisy folder: {daisy_count} images\")\n",
    "                        except PermissionError:\n",
    "                            print(f\"  ðŸŒ¼ Daisy folder: âŒ Permission denied\")\n",
    "                    \n",
    "                    elif 'dandelion' in subfolder_lower:\n",
    "                        try:\n",
    "                            dandelion_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "                            dandelion_count = len(dandelion_files)\n",
    "                            print(f\"  ðŸŒ» Dandelion folder: {dandelion_count} images\")\n",
    "                        except PermissionError:\n",
    "                            print(f\"  ðŸŒ» Dandelion folder: âŒ Permission denied\")\n",
    "                \n",
    "                if daisy_count == 0 and dandelion_count == 0:\n",
    "                    print(f\"  âš ï¸  No daisy or dandelion subfolders found\")\n",
    "                else:\n",
    "                    print(f\"  ðŸ“Š Total: {daisy_count + dandelion_count}\")\n",
    "                \n",
    "            except PermissionError:\n",
    "                print(f\"  âŒ Permission denied to access {folder_name}\")\n",
    "    \n",
    "    # Calculate overall totals\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"OVERALL SUMMARY:\")\n",
    "    total_daisy = 0\n",
    "    total_dandelion = 0\n",
    "    \n",
    "    for folder_name in os.listdir('img'):\n",
    "        folder_path = os.path.join('img', folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            try:\n",
    "                subfolders = [item for item in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, item))]\n",
    "                \n",
    "                for subfolder in subfolders:\n",
    "                    subfolder_lower = subfolder.lower()\n",
    "                    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                    \n",
    "                    if 'daisy' in subfolder_lower:\n",
    "                        try:\n",
    "                            daisy_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "                            total_daisy += len(daisy_files)\n",
    "                        except PermissionError:\n",
    "                            continue\n",
    "                    \n",
    "                    elif 'dandelion' in subfolder_lower:\n",
    "                        try:\n",
    "                            dandelion_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "                            total_dandelion += len(dandelion_files)\n",
    "                        except PermissionError:\n",
    "                            continue\n",
    "                            \n",
    "            except PermissionError:\n",
    "                continue\n",
    "    \n",
    "    print(f\"ðŸŒ¼ Total Daisy images: {total_daisy}\")\n",
    "    print(f\"ðŸŒ» Total Dandelion images: {total_dandelion}\")\n",
    "    print(f\"ðŸ“Š Grand Total: {total_daisy + total_dandelion}\")\n",
    "else:\n",
    "    print(\"img folder does not exist - cannot count daisy and dandelion images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f7abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "TRAIN_DIR = 'img/train'\n",
    "TEST_DIR = 'img/test'\n",
    "VAL_DIR = 'img/valid'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8734d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1275 images belonging to 2 classes.\n",
      "Found 364 images belonging to 2 classes.\n",
      "Found 182 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda59fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Swift GO 14\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Swift GO 14\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import keras_tuner as kt\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17850a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.95:\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a07c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(hp.Float('dropout', 0.2, 0.8, step=0.1)),\n",
    "        tf.keras.layers.Dense(hp.Int('units', 32, 512, step=32), activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    directory='my_dir',\n",
    "    project_name='mobilenet_tuning'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055fe6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 19s]\n",
      "val_accuracy: 0.44780218601226807\n",
      "\n",
      "Best val_accuracy So Far: 0.9148351550102234\n",
      "Total elapsed time: 00h 33m 32s\n",
      "WARNING:tensorflow:From c:\\Users\\Swift GO 14\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:538: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Actually perform the hyperparameter search and training\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[MyCallback()]\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae40332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 9s 806ms/step - loss: 0.2613 - accuracy: 0.9011\n",
      "Test accuracy: 0.901098906993866\n",
      "Test loss: 0.26126617193222046\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "546ac474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swift GO 14\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "best_model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecc9167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'dropout': 0.6000000000000001, 'units': 96, 'learning_rate': 0.00014824655672408831}\n",
      "Results summary\n",
      "Results in my_dir\\mobilenet_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6000000000000001\n",
      "units: 96\n",
      "learning_rate: 0.00014824655672408831\n",
      "Score: 0.9148351550102234\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6000000000000001\n",
      "units: 320\n",
      "learning_rate: 0.0031256760850773423\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.30000000000000004\n",
      "units: 384\n",
      "learning_rate: 0.0029594770617025457\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.30000000000000004\n",
      "units: 64\n",
      "learning_rate: 0.00431019016344334\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.30000000000000004\n",
      "units: 256\n",
      "learning_rate: 0.0002151735195022257\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.7\n",
      "units: 384\n",
      "learning_rate: 0.0010104015908082703\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.7\n",
      "units: 160\n",
      "learning_rate: 0.0012616129268124873\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 384\n",
      "learning_rate: 0.00032358090500847795\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.7\n",
      "units: 320\n",
      "learning_rate: 0.0010314280897923724\n",
      "Score: 0.44780218601226807\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 288\n",
      "learning_rate: 0.00018452775211528182\n",
      "Score: 0.44780218601226807\n"
     ]
    }
   ],
   "source": [
    "# Show the best trial results\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Show results summary\n",
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
